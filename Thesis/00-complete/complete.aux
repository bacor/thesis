\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@sortscheme{nyt}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\@ifundefined {etoctocstyle}{\let \etoc@startlocaltoc \@gobble \let \etoc@settocdepth \@gobble \let \etoc@depthtag \@gobble }{}}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}The cultural origins of language}{9}{chapter.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:The cultural origins of language}{{1}{9}{The cultural origins of language}{chapter.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{2}}
\abx@aux@cite{Zuidema2013}
\abx@aux@cite{Hockett1960}
\abx@aux@cite{Kirby2017}
\abx@aux@cite{Berwick2017}
\abx@aux@cite{Christiansen2016a}
\abx@aux@page{1}{10}
\abx@aux@page{2}{10}
\abx@aux@page{3}{10}
\abx@aux@page{4}{10}
\abx@aux@cite{Kirby2002}
\abx@aux@cite{Smith2014}
\abx@aux@cite{Steels2016}
\abx@aux@cite{Christiansen2016}
\abx@aux@cite{Tomasello1999}
\abx@aux@cite{Jaeger2009}
\abx@aux@page{5}{11}
\abx@aux@page{6}{11}
\abx@aux@page{7}{11}
\abx@aux@page{8}{11}
\abx@aux@page{9}{11}
\abx@aux@page{10}{11}
\abx@aux@page{11}{11}
\abx@aux@page{12}{11}
\abx@aux@page{13}{11}
\abx@aux@page{14}{11}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Source code and data}{12}{section*.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline notation}{13}{section*.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Iterated Learning}{15}{chapter.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:iterated-learning}{{2}{15}{Iterated Learning}{chapter.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{3}}
\abx@aux@cite{Brighton2002}
\abx@aux@cite{Chomsky1986}
\abx@aux@cite{Kirby2001}
\abx@aux@cite{Hurford2000}
\newlabel{SC@1}{{\caption@xref {??}{ on input line 59}}{16}{Early iterated learning models}{figure.caption.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.1}{\ignorespaces In the iterated learning model, the language produced by the previous generation serves as the primary linguistic data for the next. \par \vspace  {.5em}{\color  {lorange}Adapted from \textcite {Kirby2001}.} \relax }}{16}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:iterated-learning-illustration}{{\relax 2.1}{16}{In the iterated learning model, the language produced by the previous generation serves as the primary linguistic data for the next. \figdetails {Adapted from \textcite {Kirby2001}.} \relax }{figure.caption.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Early iterated learning models}{16}{section.2.1}}
\abx@aux@page{15}{16}
\abx@aux@page{16}{16}
\oddpage@label{1}{16}
\newlabel{fn:mind-read}{{1}{16}{Early iterated learning models}{mfootnote.1}{}}
\pgfsyspdfmark {pgfid1}{33337098}{29436305}
\abx@aux@page{19}{16}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline the emergence of compositionality, i}{16}{section*.4}}
\abx@aux@page{20}{16}
\abx@aux@cite{Cornish2011}
\abx@aux@cite{Zuidema2003}
\abx@aux@cite{Smith2002a}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Transmission bottlenecks and generalisation}{17}{section*.5}}
\oddpage@label{2}{17}
\abx@aux@page{21}{17}
\pgfsyspdfmark {pgfid3}{10886142}{28521400}
\abx@aux@page{22}{17}
\abx@aux@page{23}{17}
\abx@aux@page{24}{17}
\abx@aux@page{25}{17}
\abx@aux@page{26}{17}
\abx@aux@page{27}{17}
\abx@aux@page{28}{17}
\abx@aux@page{29}{17}
\abx@aux@cite{Culbertson2016}
\abx@aux@cite{Griffiths2005}
\abx@aux@cite{Griffiths2007}
\abx@aux@cite{Perfors2011}
\abx@aux@cite{Goodman2016}
\abx@aux@cite{Griffiths2008}
\abx@aux@cite{Kirby2014}
\abx@aux@cite{Griffiths2007a}
\abx@aux@page{30}{18}
\abx@aux@page{31}{18}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Iterated learning with Bayesian agents}{18}{section.2.2}}
\abx@aux@page{32}{18}
\abx@aux@page{33}{18}
\abx@aux@page{34}{18}
\abx@aux@page{35}{18}
\abx@aux@page{36}{18}
\oddpage@label{3}{18}
\pgfsyspdfmark {pgfid4}{13824485}{18383561}
\abx@aux@page{37}{18}
\abx@aux@cite{Kirby2004}
\abx@aux@cite{Kirby2007}
\abx@aux@cite{Burkett2010}
\abx@aux@cite{Kirby2015}
\newlabel{SC@2}{{\caption@xref {??}{ on input line 266}}{19}{Iterated learning with Bayesian agents}{figure.caption.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.2}{\ignorespaces Exponentiating a distribution moves the probability mass towards the mode. Illustrated for three different distributions. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig03}}}} \relax }}{19}{figure.caption.6}}
\newlabel{fig:FIG03}{{\relax 2.2}{19}{Exponentiating a distribution moves the probability mass towards the mode. Illustrated for three different distributions. \figdetails {\figid {fig03}} \relax }{figure.caption.6}{}}
\abx@aux@page{38}{19}
\abx@aux@page{39}{19}
\abx@aux@page{40}{19}
\abx@aux@page{41}{19}
\abx@aux@page{42}{19}
\abx@aux@page{43}{19}
\abx@aux@page{44}{19}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline The emergence of compositionality, ii}{20}{section*.7}}
\abx@aux@page{45}{20}
\abx@aux@page{46}{20}
\abx@aux@page{47}{20}
\abx@aux@page{48}{20}
\newlabel{SC@3}{{\caption@xref {??}{ on input line 354}}{21}{The emergence of compositionality, ii}{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.3}{\ignorespaces  Emergence of compositionality in the Bayesian iterated learning model of \textcite {Griffiths2007a}. On the left, the language used in every generation with H one of 252 holistic languages and C1--4 the compositional languages. On the right the relative frequency of every language up to a certain time $t$. These relative frequencies converge to the prior (orange). Larger bottlenecks (subfigures A--C) slow down convergence. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {gk01}}} WebPPL simulation with ${"α}=0.5$, ${"ε}=0.001$ and samplers (${"η}=1$).} \relax }}{21}{figure.caption.8}}
\newlabel{fig:GK01-bottlenecks}{{\relax 2.3}{21}{Emergence of compositionality in the Bayesian iterated learning model of \textcite {Griffiths2007a}. On the left, the language used in every generation with H one of 252 holistic languages and C1--4 the compositional languages. On the right the relative frequency of every language up to a certain time $t$. These relative frequencies converge to the prior (orange). Larger bottlenecks (subfigures A--C) slow down convergence. \figdetails {\figid {gk01} WebPPL simulation with $\alpha =0.5$, $\epsilon =0.001$ and samplers ($\eta =1$).} \relax }{figure.caption.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Convergence to the prior}{21}{section.2.3}}
\newlabel{eq:iterated-learning-chain}{{\relax 2.7}{21}{Convergence to the prior}{equation.2.3.7}{}}
\abx@aux@page{51}{21}
\newlabel{SC@4}{{\caption@xref {??}{ on input line 428}}{22}{Convergence to the prior}{figure.caption.9}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.4}{\ignorespaces Different Markov chains hidden in the Bayesian iterated learning model, and to which stationary distribution they converge (right). \par \vspace  {.5em}{\color  {lorange}Figure adapted from \textcite {Griffiths2007a}.} \relax }}{22}{figure.caption.9}}
\newlabel{fig:gk-markov-chains}{{\relax 2.4}{22}{Different Markov chains hidden in the Bayesian iterated learning model, and to which stationary distribution they converge (right). \figdetails {Figure adapted from \textcite {Griffiths2007a}.} \relax }{figure.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Proof of the convergence to the prior}{22}{section*.10}}
\abx@aux@page{54}{22}
\newlabel{eq:mc-interpretations}{{\relax 2.8}{22}{Proof of the convergence to the prior}{equation.2.3.8}{}}
\newlabel{eq:to-prove-convergence}{{\relax 2.9}{22}{Proof of the convergence to the prior}{equation.2.3.9}{}}
\newlabel{eq:proof-conv-to-the-prior}{{\relax 2.10}{23}{Proof of the convergence to the prior}{equation.2.3.10}{}}
\newlabel{eq:chain-joint}{{\relax 2.13}{23}{Proof of the convergence to the prior}{equation.2.3.13}{}}
\abx@aux@page{55}{23}
\abx@aux@cite{Smith2009}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Convergence to the maximum of the prior?}{24}{section*.11}}
\abx@aux@page{56}{24}
\oddpage@label{4}{24}
\pgfsyspdfmark {pgfid6}{21950775}{42189428}
\abx@aux@page{57}{24}
\abx@aux@page{58}{24}
\abx@aux@page{59}{24}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Convergent controversy}{24}{section.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Bottlenecks and weak biases}{24}{section*.12}}
\abx@aux@page{60}{24}
\abx@aux@cite{Nowak2001}
\abx@aux@cite{Niyogi2009}
\abx@aux@page{61}{25}
\abx@aux@page{62}{25}
\abx@aux@page{63}{25}
\abx@aux@page{64}{25}
\oddpage@label{5}{25}
\abx@aux@page{65}{25}
\abx@aux@page{66}{25}
\pgfsyspdfmark {pgfid7}{9689868}{30360045}
\abx@aux@page{67}{25}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline population structure and heterogenous populations}{25}{section*.13}}
\abx@aux@page{68}{25}
\abx@aux@page{69}{25}
\abx@aux@page{70}{25}
\abx@aux@page{71}{25}
\abx@aux@cite{Ferdinand2009}
\abx@aux@cite{Dediu2009}
\abx@aux@cite{Whalen2017}
\abx@aux@page{72}{26}
\abx@aux@page{73}{26}
\abx@aux@page{74}{26}
\abx@aux@page{75}{26}
\abx@aux@page{76}{26}
\abx@aux@page{77}{26}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Lineages and cumulative cultural evolution}{26}{section*.14}}
\abx@aux@page{78}{26}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Conclusions}{27}{section.2.5}}
\newlabel{desideratum:biases}{{{{(\textsc  {d}1)}}}{27}{Conclusions}{Item.3}{}}
\newlabel{desideratum:strategies}{{{{(\textsc  {d}2)}}}{27}{Conclusions}{Item.4}{}}
\newlabel{desideratum:analysable}{{{{(\textsc  {d}3)}}}{27}{Conclusions}{Item.5}{}}
\newlabel{desideratum:cultural-effects}{{{{(\textsc  {d}4)}}}{27}{Conclusions}{Item.6}{}}
\newlabel{desideratum:robust}{{{{(\textsc  {d}5)}}}{27}{Conclusions}{Item.7}{}}
\newlabel{desideratum:stable}{{{{(\textsc  {d}6)}}}{28}{Conclusions}{Item.8}{}}
\abx@aux@page{79}{28}
\newlabel{desideratum:empirical}{{{{(\textsc  {d}7)}}}{28}{Conclusions}{Item.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Naming Games}{29}{chapter.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:naming-games}{{3}{29}{Naming Games}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{4}}
\abx@aux@cite{Steels1995}
\abx@aux@cite{Steels2011}
\abx@aux@cite{Steels2012}
\abx@aux@cite{Steels2015}
\abx@aux@cite{DeVylder2006}
\abx@aux@cite{Wellens2012}
\abx@aux@page{80}{30}
\abx@aux@page{81}{30}
\abx@aux@page{82}{30}
\abx@aux@page{83}{30}
\abx@aux@page{84}{30}
\abx@aux@page{85}{30}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}The basic naming game}{30}{section.3.1}}
\abx@aux@page{86}{30}
\oddpage@label{6}{30}
\pgfsyspdfmark {pgfid8}{16387316}{10810169}
\abx@aux@cite{Oliphant1996}
\abx@aux@cite{Baronchelli2006}
\abx@aux@cite{Baronchelli2006a}
\newlabel{SC@5}{{\caption@xref {??}{ on input line 165}}{31}{The minimal strategy}{figure.caption.15}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.1}{\ignorespaces The updates of the minimal naming game illustrated. If communication fails, the hearer adds the word uttered by the speaker (bold) to its vocabulary. After a success, both empty their vocabularies and keep only the communicated word. \par \vspace  {.5em}{\color  {lorange}Figure inspired by \textcite {Wellens2012}.} \relax }}{31}{figure.caption.15}}
\newlabel{fig:ch3:minimal-naming-game-updates}{{\relax 3.1}{31}{The updates of the minimal naming game illustrated. If communication fails, the hearer adds the word uttered by the speaker (bold) to its vocabulary. After a success, both empty their vocabularies and keep only the communicated word. \figdetails {Figure inspired by \textcite {Wellens2012}.} \relax }{figure.caption.15}{}}
\abx@aux@page{87}{31}
\abx@aux@page{88}{31}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}The minimal strategy}{31}{section.3.2}}
\abx@aux@page{89}{31}
\abx@aux@cite{Baronchelli2017}
\abx@aux@page{92}{32}
\abx@aux@page{93}{32}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Phenomenology}{32}{section*.16}}
\abx@aux@page{94}{32}
\abx@aux@cite{Loreto2011}
\abx@aux@cite{DallAsta2006}
\newlabel{SC@6}{{\caption@xref {??}{ on input line 234}}{33}{Phenomenology}{figure.caption.17}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.2}{\ignorespaces  The dynamics of the minimal naming game. An sharp transition leads to convergence and the emergence of consensus. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {MNG01}}} Results shown for $N=200$; avg.\ of 300 runs, 1 std.\ shaded.} \relax }}{33}{figure.caption.17}}
\newlabel{fig:MNG01-results}{{\relax 3.2}{33}{The dynamics of the minimal naming game. An sharp transition leads to convergence and the emergence of consensus. \figdetails {\figid {MNG01} Results shown for $N=200$; avg.\ of 300 runs, 1 std.\ shaded.} \relax }{figure.caption.17}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Scaling relations and network structure}{33}{section*.18}}
\abx@aux@page{95}{33}
\abx@aux@page{96}{33}
\newlabel{eq:ch3:scaling-naming-game}{{\relax 3.1}{33}{Scaling relations and network structure}{equation.3.2.1}{}}
\abx@aux@page{97}{33}
\abx@aux@page{98}{33}
\abx@aux@page{99}{33}
\abx@aux@page{100}{33}
\abx@aux@cite{Steels2005}
\newlabel{SC@7}{{\caption@xref {??}{ on input line 347}}{34}{Lateral inhibition strategies}{table.caption.19}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {\relax 3.1}{\ignorespaces Parameter settings for four different strategies, whose behaviour is shown in figure \ref  {fig:LING01-strategies}. Note that equivalent parametrisations also exist; see main text for details. \relax }}{34}{table.caption.19}}
\newlabel{table:li-strategies}{{\relax 3.1}{34}{Parameter settings for four different strategies, whose behaviour is shown in figure \ref {fig:LING01-strategies}. Note that equivalent parametrisations also exist; see main text for details. \relax }{table.caption.19}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Lateral inhibition strategies}{34}{section.3.3}}
\abx@aux@page{101}{34}
\abx@aux@page{102}{34}
\abx@aux@page{103}{34}
\oddpage@label{7}{34}
\abx@aux@page{104}{34}
\pgfsyspdfmark {pgfid9}{30832391}{31101187}
\abx@aux@page{105}{34}
\newlabel{SC@8}{{\caption@xref {??}{ on input line 363}}{35}{Lateral inhibition strategies}{figure.caption.20}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.3}{\ignorespaces  Comparison of the four naming game strategies in table \ref  {table:li-strategies}. The the unique word count and communicative success show that all strategies reach communicative success. The stable language for the frequency strategy is not efficient. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {LING01}}} Results shown for $N=200$; avg.\ of 300 runs. $p_{\text  {success}}$ is a rolling average over a centered window of 1000 iterations.} \relax }}{35}{figure.caption.20}}
\newlabel{fig:LING01-strategies}{{\relax 3.3}{35}{Comparison of the four naming game strategies in table \ref {table:li-strategies}. The the unique word count and communicative success show that all strategies reach communicative success. The stable language for the frequency strategy is not efficient. \figdetails {\figid {LING01} Results shown for $N=200$; avg.\ of 300 runs. $p_{\text {success}}$ is a rolling average over a centered window of 1000 iterations.} \relax }{figure.caption.20}{}}
\abx@aux@page{106}{35}
\abx@aux@page{107}{35}
\oddpage@label{8}{35}
\abx@aux@page{108}{35}
\pgfsyspdfmark {pgfid10}{21776143}{24837541}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Proof of convergence}{35}{section.3.4}}
\abx@aux@page{109}{35}
\newlabel{SC@9}{{\caption@xref {??}{ on input line 438}}{36}{Proof of convergence}{figure.caption.21}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.4}{\ignorespaces A discrete distribution $\boldsymbol  {\mathbf  {{"θ}}}$ over three values corresponds to a point in the $2$-simplex, a triangular slice of $\mathbb  {R}^3$ (left). The simplex can be embedded in the plane (middle), so that every point in the triangle determines a distribution (right).  \relax }}{36}{figure.caption.21}}
\newlabel{fig:ch3:simplex}{{\relax 3.4}{36}{A discrete distribution $\vlang $ over three values corresponds to a point in the $2$-simplex, a triangular slice of $\mathbb {R}^3$ (left). The simplex can be embedded in the plane (middle), so that every point in the triangle determines a distribution (right).  \relax }{figure.caption.21}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Preliminaries}{36}{section*.22}}
\abx@aux@page{110}{36}
\oddpage@label{9}{36}
\abx@aux@page{111}{36}
\pgfsyspdfmark {pgfid13}{29222059}{26891951}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline the sampling-response model}{36}{section*.24}}
\newlabel{SC@10}{{\caption@xref {??}{ on input line 491}}{37}{Preliminaries}{figure.caption.23}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.5}{\ignorespaces  All possible frequencies of 3 words in a queue of length 4 (left) and 6 (right) form a discrete subset of the simplex. The corresponding relative frequencies are the ‘languages’ used by agents in the sampling-response model. Frequencies $(a,b,c)$ are labeled $abc$. \par \vspace  {.5em}{\color  {lorange}Figure inspired by \parencite {DeVylder2006}. } \relax }}{37}{figure.caption.23}}
\newlabel{fig:discrete-simplex}{{\relax 3.5}{37}{All possible frequencies of 3 words in a queue of length 4 (left) and 6 (right) form a discrete subset of the simplex. The corresponding relative frequencies are the ‘languages’ used by agents in the sampling-response model. Frequencies $(a,b,c)$ are labeled $abc$. \figdetails {Figure inspired by \parencite {DeVylder2006}. } \relax }{figure.caption.23}{}}
\abx@aux@page{114}{37}
\newlabel{eq:ch3:sampling-response-transition}{{\relax 3.10}{38}{the sampling-response model}{equation.3.4.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Convergence}{38}{section*.25}}
\abx@aux@page{115}{38}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Conclusions}{38}{section.3.5}}
\abx@aux@page{116}{38}
\abx@aux@cite{Baronchelli2007}
\abx@aux@page{117}{39}
\abx@aux@page{118}{39}
\abx@aux@page{119}{39}
\abx@aux@page{120}{39}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Bayesian Language Games}{41}{chapter.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:bayesian-naming-games}{{4}{41}{Bayesian Language Games}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{5}}
\abx@aux@cite{Grifoni2016}
\abx@aux@cite{Tamariz2016}
\abx@aux@cite{Reali2010}
\abx@aux@page{121}{42}
\abx@aux@page{122}{42}
\abx@aux@page{123}{42}
\abx@aux@page{124}{42}
\oddpage@label{10}{42}
\pgfsyspdfmark {pgfid15}{25539099}{43030916}
\abx@aux@page{125}{42}
\abx@aux@page{126}{42}
\oddpage@label{11}{42}
\abx@aux@page{127}{42}
\pgfsyspdfmark {pgfid16}{15892350}{38823476}
\abx@aux@page{128}{42}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}The Bayesian naming game}{42}{section.4.1}}
\abx@aux@page{129}{42}
\abx@aux@page{130}{42}
\abx@aux@page{131}{42}
\abx@aux@page{132}{42}
\newlabel{eq:ch4:bayesian-inference}{{\relax 4.1}{42}{The Bayesian naming game}{equation.4.1.1}{}}
\newlabel{SC@11}{{\caption@xref {??}{ on input line 146}}{43}{The Bayesian naming game}{figure.caption.26}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.1}{\ignorespaces  The Dirichlet distribution for various parameter settings. The Dirichlet can be parametrised by a point $\boldsymbol  {\mathbf  {{"μ}}}$ in the simplex and a scalar ${"β}$. The mean of the distribution is determined by $\boldsymbol  {\mathbf  {{"μ}}}$ and ${"β}$ influences the variance. The first row (A--D) demonstrates the effect of ${"β}$ while fixing $\boldsymbol  {\mathbf  {{"μ}}}=(\nicefrac  13, \nicefrac  13,\nicefrac  13)$; the second row (E--H) the effect of $\boldsymbol  {\mathbf  {{"μ}}}$ while keeping ${"β}=15$ fixed. Note that with ${"β}\cdot \boldsymbol  {\mathbf  {{"μ}}}= (1,1,1)$ (subfigure B) one gets a uniform distribution over the simplex. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig02}}} Figure produced using code by Thomas Boggs at \href  {https://gist.github.com/tboggs/8778945}{gist.github.com/tboggs/8778945}} \relax }}{43}{figure.caption.26}}
\newlabel{fig:dirichlet-parameterisation}{{\relax 4.1}{43}{The Dirichlet distribution for various parameter settings. The Dirichlet can be parametrised by a point $\vect \mu $ in the simplex and a scalar $\beta $. The mean of the distribution is determined by $\vect \mu $ and $\beta $ influences the variance. The first row (A--D) demonstrates the effect of $\beta $ while fixing $\vect \mu =(\nicefrac 13, \nicefrac 13,\nicefrac 13)$; the second row (E--H) the effect of $\vect \mu $ while keeping $\beta =15$ fixed. Note that with $\beta \cdot \vect \mu = (1,1,1)$ (subfigure B) one gets a uniform distribution over the simplex. \figdetails {\figid {fig02} Figure produced using code by Thomas Boggs at \href {https://gist.github.com/tboggs/8778945}{gist.github.com/tboggs/8778945}} \relax }{figure.caption.26}{}}
\abx@aux@page{133}{43}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}The Dirichlet-categorical naming game}{44}{section.4.2}}
\abx@aux@page{134}{44}
\abx@aux@page{135}{44}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Priors, beliefs, innate biases, and past experience}{44}{section*.28}}
\newlabel{eq:ch4:unraveled-updates}{{\relax 4.5}{44}{Priors, beliefs, innate biases, and past experience}{equation.4.2.5}{}}
\newlabel{SC@12}{{\caption@xref {??}{ on input line 215}}{45}{The Dirichlet-categorical naming game}{figure.caption.27}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.2}{\ignorespaces Illustration of the Bayesian naming game with all relevant concepts. See main text for details. \relax }}{45}{figure.caption.27}}
\newlabel{fig:ch4-bng-terminology}{{\relax 4.2}{45}{Illustration of the Bayesian naming game with all relevant concepts. See main text for details. \relax }{figure.caption.27}{}}
\oddpage@label{12}{45}
\pgfsyspdfmark {pgfid18}{25757328}{32327886}
\abx@aux@page{136}{45}
\abx@aux@page{137}{45}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Internal, external, expected and aggregate languages}{45}{section*.29}}
\newlabel{SC@13}{{\caption@xref {??}{ on input line 323}}{46}{Phenomenology of the \textsc {dc} naming game}{figure.caption.30}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.3}{\ignorespaces Two runs of the Bayesian Naming Game. {\color  {black}A.} The distributions of all agents (thin black lines) first diverge but eventually stabilise. They always reflect the prior (orange), {\color  {black}B.} Utterances (dots) at every time plotted over a moving average of 2000 time steps. {\color  {black}C.} The relative frequency of all utterances reflects the language adopted in the population. See main text for more details. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig05}}} $K=16$, $N=15$, $b=1$, ${"β}=18$, ${"η}={"ζ}=1$, ${"γ}=\infty $} \relax }}{46}{figure.caption.30}}
\newlabel{fig:FIG05}{{\relax 4.3}{46}{Two runs of the Bayesian Naming Game. \subfig {A} The distributions of all agents (thin black lines) first diverge but eventually stabilise. They always reflect the prior (orange), \subfig {B} Utterances (dots) at every time plotted over a moving average of 2000 time steps. \subfig {C} The relative frequency of all utterances reflects the language adopted in the population. See main text for more details. \figdetails {\figid {fig05} $K=16$, $N=15$, $b=1$, $\beta =18$, $\eta =\zeta =1$, $\gamma =\infty $} \relax }{figure.caption.30}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Phenomenology of the \textsc  {dc} naming game}{46}{section.4.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline three-stage evolution}{46}{section*.31}}
\oddpage@label{13}{47}
\pgfsyspdfmark {pgfid19}{17327020}{42189428}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline measuring the dynamics}{47}{section*.32}}
\oddpage@label{14}{47}
\pgfsyspdfmark {pgfid20}{23718898}{32850575}
\newlabel{eq:ch4:coherence}{{\relax 4.9}{47}{measuring the dynamics}{equation.4.3.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline convergence}{47}{section*.33}}
\abx@aux@page{138}{47}
\abx@aux@cite{Baronchelli2008}
\newlabel{SC@14}{{\caption@xref {??}{ on input line 436}}{48}{convergence}{figure.caption.34}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.4}{\ignorespaces The Dirichlet-categorical name converges to a stable, coherent language. {\color  {black}A.} The distance between expected languages vanishes, but the aggregate language deviates from the bias. {\color  {black}B.} Coherence initially drops, but then increases to 1. The black line illustrates the \emph  {reflection of the bias}. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {bng02}}} $K=40$, $N=20$, ${"η}={"ζ}=1$, ${"γ}=\infty $, ${"β}=40$} \relax }}{48}{figure.caption.34}}
\newlabel{fig:BNG02-results}{{\relax 4.4}{48}{The Dirichlet-categorical name converges to a stable, coherent language. \subfig {A} The distance between expected languages vanishes, but the aggregate language deviates from the bias. \subfig {B} Coherence initially drops, but then increases to 1. The black line illustrates the \emph {reflection of the bias}. \figdetails {\figid {bng02} $K=40$, $N=20$, $\eta =\zeta =1$, $\gamma =\infty $, $\beta =40$} \relax }{figure.caption.34}{}}
\newlabel{SC@15}{{\caption@xref {??}{ on input line 458}}{48}{convergence}{figure.caption.35}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.5}{\ignorespaces Effects of the language, population and bottleneck size on convergence time, probed by the critical points $t_{\text  {max}}$ and $t_{\text  {int}}$. See main text for details. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {bng03}}} Parameters are fixed at $N=5$, $K=10$ and $b=10$, if they are not varied. ${"η}={"ζ}=1$, ${"γ}=\infty $, ${"β}=100$.} \relax }}{48}{figure.caption.35}}
\newlabel{fig:BNG03-effects-params-on-convergence}{{\relax 4.5}{48}{Effects of the language, population and bottleneck size on convergence time, probed by the critical points $t_{\text {max}}$ and $t_{\text {int}}$. See main text for details. \figdetails {\figid {bng03} Parameters are fixed at $N=5$, $K=10$ and $b=10$, if they are not varied. $\eta =\zeta =1$, $\gamma =\infty $, $\beta =100$.} \relax }{figure.caption.35}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline scaling}{48}{section*.36}}
\abx@aux@page{139}{48}
\abx@aux@page{140}{48}
\abx@aux@cite{Regier2015}
\newlabel{SC@16}{{\caption@xref {??}{ on input line 496}}{49}{scaling}{figure.caption.37}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.6}{\ignorespaces {\color  {black}A.} Different runs of evolutionary history result in different stable languages (thin black lines) that all reflect the prior (orange) in the sense that cultural evolution reproduces the prior \emph  {on average} over many runs. This is illustrated with six differently shaped priors. {\color  {black}B.} How well the languages reflect the prior is regulated by the strength of the prior (${"β}$). \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {bng04/07}}} $K=20$, $N=10$, $b=10$, ${"ζ}={"η}=1$, ${"γ}=\infty $, ${"β}=100$} \relax }}{49}{figure.caption.37}}
\newlabel{fig:BNG04-07-reflection-prior}{{\relax 4.6}{49}{\subfig {A} Different runs of evolutionary history result in different stable languages (thin black lines) that all reflect the prior (orange) in the sense that cultural evolution reproduces the prior \emph {on average} over many runs. This is illustrated with six differently shaped priors. \subfig {B} How well the languages reflect the prior is regulated by the strength of the prior ($\beta $). \figdetails {\figid {bng04/07} $K=20$, $N=10$, $b=10$, $\zeta =\eta =1$, $\gamma =\infty $, $\beta =100$} \relax }{figure.caption.37}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline reflection of the bias}{49}{section*.38}}
\abx@aux@page{141}{49}
\abx@aux@page{142}{49}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Language and production strategies}{49}{section.4.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline language strategies}{49}{section*.39}}
\newlabel{SC@17}{{\caption@xref {??}{ on input line 566}}{50}{language strategies}{figure.caption.40}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.7}{\ignorespaces Exaggerating (or exponentiating) a Dirichlet distribution shrinks the variance and as ${"η}$ grows, the mean approaches the mode. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig02}}}} \relax }}{50}{figure.caption.40}}
\newlabel{fig:dirichlet-eta}{{\relax 4.7}{50}{Exaggerating (or exponentiating) a Dirichlet distribution shrinks the variance and as $\eta $ grows, the mean approaches the mode. \figdetails {\figid {fig02}} \relax }{figure.caption.40}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline production strategies}{50}{section*.41}}
\abx@aux@page{143}{50}
\oddpage@label{15}{50}
\abx@aux@page{144}{50}
\abx@aux@page{145}{50}
\pgfsyspdfmark {pgfid21}{33399349}{9968681}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Bayesian language games}{51}{section.4.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Ingredient 1: random walks}{51}{section*.43}}
\abx@aux@page{146}{51}
\oddpage@label{16}{51}
\pgfsyspdfmark {pgfid23}{9665249}{13334633}
\oddpage@label{17}{51}
\pgfsyspdfmark {pgfid24}{19090372}{9968681}
\abx@aux@cite{DeBoer1999}
\abx@aux@cite{Smith2002}
\abx@aux@cite{Rodriguez2007}
\abx@aux@cite{Juckett1993}
\newlabel{SC@18}{{\caption@xref {??}{ on input line 665}}{52}{Bayesian language games}{figure.caption.42}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.8}{\ignorespaces The proposed transmission model, a random walk through the population, combines the transmission chains used in iterated learning with the homogeneous mixing from the naming game. \relax }}{52}{figure.caption.42}}
\newlabel{fig:ch4:population-structures}{{\relax 4.8}{52}{The proposed transmission model, a random walk through the population, combines the transmission chains used in iterated learning with the homogeneous mixing from the naming game. \relax }{figure.caption.42}{}}
\newlabel{SC@19}{{\caption@xref {??}{ on input line 729}}{52}{Ingredient 2: vary the life expectancy}{figure.caption.45}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.9}{\ignorespaces Different hazard functions. The more realistic (continuous/discrete) Weibull hazard is better approximated by a degenerate than a constant hazard function. \relax }}{52}{figure.caption.45}}
\newlabel{fig:ch4:hazards}{{\relax 4.9}{52}{Different hazard functions. The more realistic (continuous/discrete) Weibull hazard is better approximated by a degenerate than a constant hazard function. \relax }{figure.caption.45}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Ingredient 2: vary the life expectancy}{52}{section*.44}}
\abx@aux@page{147}{52}
\abx@aux@page{148}{52}
\abx@aux@page{149}{52}
\abx@aux@page{150}{52}
\oddpage@label{18}{53}
\pgfsyspdfmark {pgfid25}{19993021}{44713892}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}Characterising Bayesian language games}{53}{section.4.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Varying life expectancy: between \textsc  {il} and \textsc  {ng}’s}{53}{section*.47}}
\newlabel{SC@20}{{\caption@xref {??}{ on input line 801}}{54}{Characterising Bayesian language games}{figure.caption.46}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.10}{\ignorespaces Typical outcomes of the Dirichlet-Categorical language game for the extreme strategies (sample--sample, \textsc  {map}--sample, sample--\textsc  {map}, \textsc  {map--map}) in populations with immediate turnover (\textsc  {a}, iterated learning, ${"γ}=1$), no turnover (\textsc  {b}, naming game, ${"γ}=\infty $) and two intermediate turnovers (\textsc  {c} and \textsc  {d}). See the main text for a discussion. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig08}}} $K = 16$, $N = 15$, $b = 1$, $T=10 000$} \relax }}{54}{figure.caption.46}}
\newlabel{fig:FIG08-bng-overview}{{\relax 4.10}{54}{Typical outcomes of the Dirichlet-Categorical language game for the extreme strategies (sample--sample, \textsc {map}--sample, sample--\textsc {map}, \textsc {map--map}) in populations with immediate turnover (\textsc {a}, iterated learning, $\gamma =1$), no turnover (\textsc {b}, naming game, $\gamma =\infty $) and two intermediate turnovers (\textsc {c} and \textsc {d}). See the main text for a discussion. \figdetails {\figid {fig08} $K = 16$, $N = 15$, $b = 1$, $T=10 000$} \relax }{figure.caption.46}{}}
\abx@aux@page{151}{54}
\newlabel{SC@21}{{\caption@xref {??}{ on input line 860}}{55}{Varying life expectancy: between \textsc {il} and \textsc {ng}’s}{figure.caption.48}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.11}{\ignorespaces Gradual language change in the Bayesian language game for a particular choice of parameters. The effect seems brittle: slightly different parameter settings can give the kind of behaviour shown when ${"γ}=\infty $. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig11}}} $K = 20$, $N = 10$, $b = 2$, ${"β}= 40$, ${"γ}=700$, ${"η}=2$, ${"ζ}=1$, deterministic hazard.} \relax }}{55}{figure.caption.48}}
\newlabel{fig:FIG11-BNG-language-change}{{\relax 4.11}{55}{Gradual language change in the Bayesian language game for a particular choice of parameters. The effect seems brittle: slightly different parameter settings can give the kind of behaviour shown when $\gamma =\infty $. \figdetails {\figid {fig11} $K = 20$, $N = 10$, $b = 2$, $\beta = 40$, $\gamma =700$, $\eta =2$, $\zeta =1$, deterministic hazard.} \relax }{figure.caption.48}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Extreme strategies for the Bayesian naming game}{55}{section*.49}}
\abx@aux@page{152}{55}
\abx@aux@page{153}{56}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.7}Conclusions}{56}{section.4.7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline related work}{57}{section*.50}}
\abx@aux@page{154}{57}
\abx@aux@page{155}{57}
\oddpage@label{19}{57}
\pgfsyspdfmark {pgfid26}{8232383}{29475690}
\abx@aux@page{156}{57}
\abx@aux@page{157}{57}
\abx@aux@page{158}{57}
\abx@aux@page{159}{57}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Numeral systems}{59}{chapter.5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:numerals}{{5}{59}{Numeral systems}{chapter.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{6}}
\abx@aux@cite{Comrie2013}
\abx@aux@cite{Dediu2013}
\abx@aux@cite{Tamariz2017}
\abx@aux@cite{Kirby2008}
\abx@aux@cite{Regier2007}
\abx@aux@cite{Kemp2012}
\abx@aux@cite{Khetarpal2013}
\abx@aux@cite{Xu2014}
\abx@aux@cite{Levinson2012}
\abx@aux@cite{Xu2010}
\abx@aux@cite{Carstensen2015}
\abx@aux@cite{Baronchelli2010}
\abx@aux@page{160}{60}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Balancing expressivity and simplicity}{60}{section.5.1}}
\abx@aux@page{161}{60}
\abx@aux@page{162}{60}
\abx@aux@page{163}{60}
\abx@aux@page{164}{60}
\abx@aux@page{165}{60}
\abx@aux@page{166}{60}
\abx@aux@page{167}{60}
\abx@aux@page{170}{60}
\abx@aux@page{171}{60}
\abx@aux@page{172}{60}
\abx@aux@page{173}{60}
\abx@aux@cite{VonMengden2008}
\abx@aux@cite{Hurford1975}
\abx@aux@cite{Hurford1987}
\abx@aux@cite{Greenberg1978}
\abx@aux@cite{Hammarstrom2009}
\abx@aux@cite{Hanke2010}
\newlabel{SC@22}{{\caption@xref {??}{ on input line 69}}{61}{Balancing expressivity and simplicity}{figure.caption.51}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.1}{\ignorespaces Transmission pressures for learnable languages, resulting in systematic underspecification (left). Introducing a pressure for expressivity results in compositional structure (right). \par \vspace  {.5em}{\color  {lorange}Figure reproduced from \textcite {Kirby2008} without permission. }\relax }}{61}{figure.caption.51}}
\newlabel{fig:ch5:kirby}{{\relax 5.1}{61}{Transmission pressures for learnable languages, resulting in systematic underspecification (left). Introducing a pressure for expressivity results in compositional structure (right). \figdetails {Figure reproduced from \textcite {Kirby2008} without permission. \label {fig:ch5:kirby}}\relax }{figure.caption.51}{}}
\abx@aux@page{174}{61}
\abx@aux@page{175}{61}
\abx@aux@page{176}{61}
\abx@aux@page{177}{61}
\abx@aux@page{178}{61}
\abx@aux@page{179}{61}
\abx@aux@page{180}{61}
\abx@aux@page{181}{61}
\newlabel{SC@23}{{\caption@xref {??}{ on input line 140}}{62}{Defining numerals}{figure.caption.53}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.2}{\ignorespaces Numerals are numerically specific, systematic quantifiers. \par \vspace  {.5em}{\color  {lorange}Reproduced from \textcite {VonMengden2008} without permission.} \relax }}{62}{figure.caption.53}}
\newlabel{fig:ch5:quantifiers}{{\relax 5.2}{62}{Numerals are numerically specific, systematic quantifiers. \figdetails {Reproduced from \textcite {VonMengden2008} without permission.} \relax }{figure.caption.53}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}An introduction to numeral systems}{62}{section.5.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Defining numerals}{62}{section*.52}}
\abx@aux@page{182}{62}
\abx@aux@page{185}{62}
\abx@aux@page{186}{62}
\oddpage@label{20}{62}
\pgfsyspdfmark {pgfid27}{29394962}{10810169}
\abx@aux@page{187}{62}
\abx@aux@cite{Comrie2011}
\abx@aux@cite{Calude2016}
\abx@aux@page{188}{63}
\oddpage@label{21}{63}
\pgfsyspdfmark {pgfid28}{25023900}{45420655}
\abx@aux@page{189}{63}
\abx@aux@page{190}{63}
\abx@aux@page{191}{63}
\abx@aux@page{192}{63}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Simple numerals, complex numerals and bases}{63}{section*.54}}
\abx@aux@page{193}{63}
\abx@aux@page{194}{63}
\abx@aux@page{195}{63}
\abx@aux@page{196}{63}
\abx@aux@page{197}{63}
\abx@aux@page{198}{63}
\abx@aux@cite{Comrie1999}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Isolated, mixed and additive bases}{64}{section*.55}}
\abx@aux@page{199}{64}
\abx@aux@page{200}{64}
\abx@aux@page{201}{64}
\abx@aux@page{202}{64}
\abx@aux@page{203}{64}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Exponentiation and mathematical bases.}{64}{section*.56}}
\abx@aux@page{204}{64}
\abx@aux@page{205}{64}
\abx@aux@page{206}{64}
\abx@aux@page{207}{65}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Subtraction, division and fractions}{65}{section*.57}}
\abx@aux@page{208}{65}
\abx@aux@page{209}{65}
\abx@aux@page{210}{65}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Overcounting and overrunning.}{65}{section*.58}}
\abx@aux@cite{Zhou2015}
\abx@aux@cite{Heine2002}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline order}{66}{section*.59}}
\abx@aux@page{211}{66}
\abx@aux@page{212}{66}
\abx@aux@page{213}{66}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Continuity of the counting sequence}{66}{section*.60}}
\oddpage@label{22}{66}
\abx@aux@page{214}{66}
\pgfsyspdfmark {pgfid29}{18343731}{36176910}
\abx@aux@page{215}{66}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline The packing strategy}{66}{section*.61}}
\abx@aux@page{216}{66}
\abx@aux@page{217}{66}
\abx@aux@page{218}{66}
\abx@aux@cite{Hurford2007}
\abx@aux@cite{Feigenson2004}
\abx@aux@cite{Dehaene2011}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline A decimal world}{67}{section*.62}}
\abx@aux@page{219}{67}
\abx@aux@page{220}{67}
\abx@aux@page{221}{67}
\abx@aux@page{222}{67}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}The evolution of numeral systems}{67}{section.5.3}}
\abx@aux@page{223}{67}
\abx@aux@page{224}{67}
\abx@aux@page{225}{67}
\abx@aux@page{226}{67}
\abx@aux@page{227}{67}
\abx@aux@page{228}{67}
\abx@aux@page{229}{67}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline 1. Subitising and simple numerals}{67}{section*.63}}
\abx@aux@page{230}{67}
\abx@aux@page{231}{67}
\abx@aux@cite{Hurford2001}
\abx@aux@cite{Dehaene1992}
\abx@aux@page{232}{68}
\abx@aux@page{233}{68}
\abx@aux@page{234}{68}
\abx@aux@page{235}{68}
\abx@aux@page{236}{68}
\abx@aux@page{237}{68}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline 2. Counting and the emergence of numeracy}{68}{section*.64}}
\abx@aux@page{238}{68}
\abx@aux@page{239}{68}
\abx@aux@page{240}{68}
\abx@aux@page{241}{68}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline 3. Serialisation}{68}{section*.65}}
\abx@aux@page{242}{68}
\abx@aux@page{243}{68}
\abx@aux@page{244}{69}
\abx@aux@page{245}{69}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline 4. Functional elements}{69}{section*.66}}
\abx@aux@page{246}{69}
\abx@aux@page{247}{69}
\abx@aux@page{248}{69}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Conclusions}{69}{section.5.4}}
\abx@aux@page{249}{69}
\abx@aux@page{250}{69}
\abx@aux@page{251}{69}
\abx@aux@page{252}{70}
\abx@aux@page{253}{70}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Emergent numeral systems}{71}{chapter.6}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:counting-games}{{6}{71}{Emergent numeral systems}{chapter.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{7}}
\abx@aux@page{254}{72}
\oddpage@label{23}{72}
\pgfsyspdfmark {pgfid30}{22915881}{37140500}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.1}Hurford’s base games}{72}{section.6.1}}
\oddpage@label{24}{72}
\pgfsyspdfmark {pgfid31}{33866550}{19457722}
\newlabel{eq:favoured-base-criterion}{{\relax 6.1}{72}{Hurford’s base games}{equation.6.1.1}{}}
\oddpage@label{25}{72}
\pgfsyspdfmark {pgfid32}{16330552}{15017609}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline additive base game}{73}{section*.67}}
\abx@aux@page{255}{73}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline multiplicative base game}{73}{section*.68}}
\abx@aux@page{256}{73}
\newlabel{SC@24}{{\caption@xref {??}{ on input line 198}}{74}{multiplicative base game}{figure.caption.69}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.1}{\ignorespaces Comparison between the Additive Base Game (black) and the Multiplicative Base Game (orange). The dynamics of the two games are remarkably similar. Dynamics are visualized using {\color  {black}A.} the base counts of all possible bases for the Additive Base Game only (the Multiplicative case looks extremely similar); {\color  {black}B.} the total base counts; {\color  {black}C.} the unique base count; and {\color  {black}D.} the probability of successful communication. See main text for details. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {hur03}}} Results shown for $N=200$, $B=10$, ${"ξ}=1$; avg.\ of 600 runs; 1 std.\ shaded. } \relax }}{74}{figure.caption.69}}
\newlabel{fig:HUR03-results}{{\relax 6.1}{74}{Comparison between the Additive Base Game (black) and the Multiplicative Base Game (orange). The dynamics of the two games are remarkably similar. Dynamics are visualized using \subfig {A} the base counts of all possible bases for the Additive Base Game only (the Multiplicative case looks extremely similar); \subfig {B} the total base counts; \subfig {C} the unique base count; and \subfig {D} the probability of successful communication. See main text for details. \figdetails {\figid {hur03} Results shown for $N=200$, $B=10$, $\xi =1$; avg.\ of 600 runs; 1 std.\ shaded. } \relax }{figure.caption.69}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Basic Phenomenology}{74}{section*.70}}
\abx@aux@page{257}{74}
\newlabel{SC@25}{{\caption@xref {??}{ on input line 303}}{75}{Implicit biases and external constraints}{figure.caption.72}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.2}{\ignorespaces In the additive base game, the probability of using a base without any past experience (i.e., no preferences) is strongly skewed towards the highest base. The game has a strong implicit prior for using high bases. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig10}}} The ‘simulation’ is the rel. freq. of 100 000 samples.} \relax }}{75}{figure.caption.72}}
\newlabel{fig:FIG10-base-game-bias.pdf}{{\relax 6.2}{75}{In the additive base game, the probability of using a base without any past experience (i.e., no preferences) is strongly skewed towards the highest base. The game has a strong implicit prior for using high bases. \figdetails {\figid {fig10} The ‘simulation’ is the rel. freq. of 100 000 samples.} \relax }{figure.caption.72}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.2}Domain adaptivity in the base games}{75}{section.6.2}}
\newlabel{eq:ch6:bias-additive-naming-game}{{\relax 6.4}{75}{Domain adaptivity in the base games}{equation.6.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Implicit biases and external constraints}{75}{section*.71}}
\oddpage@label{26}{75}
\pgfsyspdfmark {pgfid33}{17522429}{17582725}
\newlabel{SC@26}{{\caption@xref {??}{ on input line 321}}{76}{Implicit biases and external constraints}{figure.caption.73}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.3}{\ignorespaces The additive base game in populations biased towards using base 7 (left) or base 8 (right), with varying initial score $s_0$ (higher scores indicate stronger bias). The figure illustrates that the biases implicit in the domain and the biases of the agents work differently: agents cannot overcome the former (see main text for details). Note: averages over 300 runs are shown and for $s_0=1.5$ individual runs convert to either base 10 or base 8. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {hur05}}} Results shown for $N=200$, ${"η}=1$, $n_{\text  {max}}=46$; avg.\ of 300 runs, 1 std.\ shaded.} \relax }}{76}{figure.caption.73}}
\newlabel{fig:effect-initial-conditions}{{\relax 6.3}{76}{The additive base game in populations biased towards using base 7 (left) or base 8 (right), with varying initial score $s_0$ (higher scores indicate stronger bias). The figure illustrates that the biases implicit in the domain and the biases of the agents work differently: agents cannot overcome the former (see main text for details). Note: averages over 300 runs are shown and for $s_0=1.5$ individual runs convert to either base 10 or base 8. \figdetails {\figid {hur05} Results shown for $N=200$, $\eta =1$, $n_{\text {max}}=46$; avg.\ of 300 runs, 1 std.\ shaded.} \relax }{figure.caption.73}{}}
\newlabel{SC@27}{{\caption@xref {??}{ on input line 416}}{77}{Domain adaptivity in the multiplicative base game}{figure.caption.75}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.4}{\ignorespaces Domain adaptivity in the multiplicative base game. Figure {\color  {black}A.} shows the distribution over outcomes (adopted bases) for every the domain $I(n_{\text  {max}}) = \{11, \dots  , n_{\text  {max}}\}$. Note that the plot shows 99 distributions, one for each $n_{\text  {max}}$. The game appears to exaggerate certain biases implicit in the domain. Figure {\color  {black}B.} shows an approximation of these biases: the probability that an expression randomly drawn from all expressions for numbers in $I(n_{\text  {max}})$ uses base $b$. Details are in the main text. \par \vspace  {.5em}{\color  {lorange} \textsc  {\textbf  {\lowercase {hur07}}} Results shown for $N=200$, ${"η}=1$. Each of the 99 distributions is the average over 600 runs.  }\relax }}{77}{figure.caption.75}}
\newlabel{fig:HUR07-results}{{\relax 6.4}{77}{Domain adaptivity in the multiplicative base game. Figure \subfig {A} shows the distribution over outcomes (adopted bases) for every the domain $I(n_{\text {max}}) = \{11, \dots , n_{\text {max}}\}$. Note that the plot shows 99 distributions, one for each $n_{\text {max}}$. The game appears to exaggerate certain biases implicit in the domain. Figure \subfig {B} shows an approximation of these biases: the probability that an expression randomly drawn from all expressions for numbers in $I(n_{\text {max}})$ uses base $b$. Details are in the main text. \figdetails { \figid {hur07} Results shown for $N=200$, $\eta =1$. Each of the 99 distributions is the average over 600 runs. \label {fig:HUR07-results} }\relax }{figure.caption.75}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Domain adaptivity in the multiplicative base game}{77}{section*.74}}
\oddpage@label{27}{77}
\pgfsyspdfmark {pgfid34}{26294275}{23592116}
\oddpage@label{28}{77}
\pgfsyspdfmark {pgfid35}{6481243}{21067652}
\newlabel{eq:ch6:base-b-expressions}{{\relax 6.5}{78}{Domain adaptivity in the multiplicative base game}{equation.6.2.5}{}}
\newlabel{SC@28}{{\caption@xref {??}{ on input line 532}}{79}{Counting games}{figure.caption.76}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.5}{\ignorespaces A naming game with three objects is just the sum of three independent single-word \textsc  {ng}’s when there is no homonymy. Dashed lines show the statistics per object; solid lines for the ‘total’ game: the sum of the dashed lines. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig07}}} Results shown for 1 run; $N=200$, using the current strategy.} \relax }}{79}{figure.caption.76}}
\newlabel{fig:multi-word-minimal-naming-game}{{\relax 6.5}{79}{A naming game with three objects is just the sum of three independent single-word \textsc {ng}’s when there is no homonymy. Dashed lines show the statistics per object; solid lines for the ‘total’ game: the sum of the dashed lines. \figdetails {\figid {fig07} Results shown for 1 run; $N=200$, using the current strategy.} \relax }{figure.caption.76}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.3}Counting games}{79}{section.6.3}}
\abx@aux@page{258}{79}
\abx@aux@page{259}{79}
\oddpage@label{29}{80}
\pgfsyspdfmark {pgfid36}{34496575}{46396868}
\newlabel{SC@29}{{\caption@xref {??}{ on input line 641}}{81}{Counting games}{figure.caption.77}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.6}{\ignorespaces Dynamics of the three counting games measured by the number of unique pairs and the initial segment length. In all cases the population develops a counting sequence, but the dynamics are strikingly different. See main text for details. \par \vspace  {.5em}{\color  {lorange}Results shown for $N=200$; avg.\ of 600 runs, 1 std.\ shaded.} \relax }}{81}{figure.caption.77}}
\newlabel{fig:counting-games}{{\relax 6.6}{81}{Dynamics of the three counting games measured by the number of unique pairs and the initial segment length. In all cases the population develops a counting sequence, but the dynamics are strikingly different. See main text for details. \figdetails {Results shown for $N=200$; avg.\ of 600 runs, 1 std.\ shaded.} \relax }{figure.caption.77}{}}
\oddpage@label{30}{81}
\pgfsyspdfmark {pgfid37}{21987993}{32428511}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Simple numerals, and beyond?}{81}{section*.78}}
\abx@aux@page{260}{81}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.4}Conclusions}{82}{section.6.4}}
\abx@aux@page{261}{82}
\abx@aux@page{262}{82}
\oddpage@label{31}{82}
\pgfsyspdfmark {pgfid38}{29613255}{10810169}
\oddpage@label{32}{83}
\abx@aux@page{263}{83}
\pgfsyspdfmark {pgfid39}{24213645}{48079844}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Mechanisms and interpretations}{83}{section*.79}}
\abx@aux@page{264}{83}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions}{85}{chapter.7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conclusions}{{7}{85}{Conclusions}{chapter.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Bayesian naming game}{86}{section*.80}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Bayesian language game}{86}{section*.81}}
\newlabel{SC@30}{{\caption@xref {??}{ on input line 79}}{87}{Bayesian language game}{figure.caption.82}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.1}{\ignorespaces Typical outcomes of the Dirichlet-Categorical language name for the extreme strategies (sample--sample, \textsc  {map}--sample, sample--\textsc  {map}, \textsc  {map--map}) in populations with immediate turnover (\textsc  {a}, iterated learning, ${"γ}=1$), no turnover (\textsc  {b}, naming game, ${"γ}=\infty $) and two intermediate turnovers (\textsc  {c} and \textsc  {d}). \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig08}}} $K = 16$, $N = 15$, $b = 1$, $T=10 000$} \relax }}{87}{figure.caption.82}}
\newlabel{fig:ch7:FIG08-bng-overview}{{\relax 7.1}{87}{Typical outcomes of the Dirichlet-Categorical language name for the extreme strategies (sample--sample, \textsc {map}--sample, sample--\textsc {map}, \textsc {map--map}) in populations with immediate turnover (\textsc {a}, iterated learning, $\gamma =1$), no turnover (\textsc {b}, naming game, $\gamma =\infty $) and two intermediate turnovers (\textsc {c} and \textsc {d}). \figdetails {\figid {fig08} $K = 16$, $N = 15$, $b = 1$, $T=10 000$} \relax }{figure.caption.82}{}}
\oddpage@label{33}{87}
\pgfsyspdfmark {pgfid40}{25176702}{11416998}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline empirical validity}{88}{section*.83}}
\abx@aux@page{265}{88}
\oddpage@label{34}{88}
\pgfsyspdfmark {pgfid41}{21711113}{12493145}
\abx@aux@page{266}{88}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.1}Main contributions}{89}{section.7.1}}
\abx@aux@page{267}{89}
\abx@aux@cite{Ghahramani2015}
\abx@aux@page{268}{90}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.2}Future work}{90}{section.7.2}}
\abx@aux@page{269}{90}
\newlabel{fw:measures-bng}{{7.2}{90}{Future work}{section.7.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Other Bayesian naming games}{90}{section*.84}}
\abx@aux@page{270}{90}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Connections to biological evolution}{91}{section*.85}}
\abx@aux@page{271}{91}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Nonparametric extension of the Bayesian Naming Game}{91}{section*.86}}
\abx@aux@page{272}{91}
\abx@aux@page{273}{91}
\abx@aux@page{274}{91}
\abx@aux@page{275}{91}
\abx@aux@page{276}{91}
\abx@aux@page{277}{91}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Mathematical analysis of the Bayesian Naming Game}{91}{section*.87}}
\abx@aux@page{278}{92}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\nonumberline Appendices}{93}{Appendix*.88}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\etoc@startlocaltoc{9}}
\abx@aux@cite{Madsen2015a}
\abx@aux@cite{Norris1997}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A}Converging Markov Chains}{94}{section.1.7.A}}
\newlabel{app:markov-chains}{{A}{94}{Converging Markov Chains}{section.1.7.A}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Rainy and sunny days}{94}{section*.89}}
\oddpage@label{35}{94}
\abx@aux@page{279}{94}
\abx@aux@page{280}{94}
\pgfsyspdfmark {pgfid42}{23348965}{38999955}
\newlabel{eq:markov-example}{{\relax 7.1}{94}{Rainy and sunny days}{equation.1.7.A.1}{}}
\newlabel{eq:markov-assumption}{{\relax 7.2}{94}{Rainy and sunny days}{equation.1.7.A.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline limiting and stationary distributions}{95}{section*.90}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Aperiodicity and irreducibility}{95}{section*.91}}
\oddpage@label{36}{96}
\pgfsyspdfmark {pgfid46}{21031073}{36263544}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline ergodicity}{96}{section*.92}}
\newlabel{thm:convergence}{{1}{96}{1.8.3 in \cite {Norris1997}}{theorem.1}{}}
\abx@aux@page{281}{96}
\abx@aux@page{282}{96}
\abx@aux@page{283}{97}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {B}Lateral Inhibition Strategies}{97}{section.1.7.B}}
\newlabel{app:li-strategies}{{B}{97}{Lateral Inhibition Strategies}{section.1.7.B}{}}
\abx@aux@page{284}{97}
\abx@aux@page{285}{97}
\newlabel{SC@31}{{\caption@xref {??}{ on input line 51}}{98}{Lateral Inhibition Strategies}{figure.caption.93}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.2}{\ignorespaces {\color  {black}A.} The effect of ${"δ}_{\text  {inh}}$ keeping ${"δ}_{\text  {inc}} = 1$ fixed. It interpolates between the minimal strategy and frequency strategy. {\color  {black}B.} the effect of ${"δ}_{\text  {inc}}$ for ${"δ}_{\text  {inh}} = 1$ fixed. For large ${"δ}_{\text  {inc}}$, the inhibition is rendered ineffective. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {LING03}}} Results shown for $N=200$, ${"δ}_{\text  {dec}} = 0$, $s_{\text  {init}} = 1$, $s_{\text  {max}} = \infty $; avg.\ of 300 runs. $p_{\text  {success}}$ is moreover a rolling average over a centered window of 1000 iterations. } \relax }}{98}{figure.caption.93}}
\newlabel{fig:delta-inh-vs-delta-inc}{{\relax 7.2}{98}{\subfig {A} The effect of $\delta _{\text {inh}}$ keeping $\delta _{\text {inc}} = 1$ fixed. It interpolates between the minimal strategy and frequency strategy. \subfig {B} the effect of $\delta _{\text {inc}}$ for $\delta _{\text {inh}} = 1$ fixed. For large $\delta _{\text {inc}}$, the inhibition is rendered ineffective. \figdetails {\figid {LING03} Results shown for $N=200$, $\delta _{\text {dec}} = 0$, $s_{\text {init}} = 1$, $s_{\text {max}} = \infty $; avg.\ of 300 runs. $p_{\text {success}}$ is moreover a rolling average over a centered window of 1000 iterations. } \relax }{figure.caption.93}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {C}Mathematical details of Dirichlet-categorical \textsc  {ng}}{98}{section.1.7.C}}
\newlabel{app:bng}{{C}{98}{Mathematical details of Dirichlet-categorical \textsc {ng}}{section.1.7.C}{}}
\abx@aux@cite{Bishop2006}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Dirichlet and categorical distributions}{99}{subsection.1.7.C.1}}
\abx@aux@page{286}{99}
\newlabel{eq:app-bng:joint-iid-categoricals}{{\relax 7.12}{99}{Dirichlet and categorical distributions}{equation.1.7.C.12}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Dirichlet-categorical distribution}{99}{section*.94}}
\newlabel{eq:app-bng:joint-density-dirichlet}{{\relax 7.17}{100}{Dirichlet-categorical distribution}{equation.1.7.C.17}{}}
\newlabel{eq:app-bng:deriv-continue}{{\relax 7.24}{100}{Dirichlet-categorical distribution}{equation.1.7.C.24}{}}
\newlabel{eq:app-bng:dirichlet-categorical-compound}{{\relax 7.25}{100}{Dirichlet-categorical distribution}{equation.1.7.C.25}{}}
\newlabel{eq:app-bng:predictive}{{\relax 7.28}{101}{Dirichlet-categorical distribution}{equation.1.7.C.28}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Exponentiated distributions}{101}{subsection.1.7.C.2}}
\newlabel{eq:app-bng:exponentiated-dirichlet}{{\relax 7.32}{101}{Exponentiated distributions}{equation.1.7.C.32}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline The difficult case ${"ζ}=\infty $}{101}{section*.95}}
\newlabel{SC@32}{{\caption@xref {??}{ on input line 331}}{102}{The difficult case $\zeta =\infty $}{figure.caption.96}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.3}{\ignorespaces The posterior distribution $p(\boldsymbol  {\mathbf  {{"θ}}}\mid x)$ for various $x$ if ${"ζ}=\infty $, that is, if agents always pick the most likely word. The posterior restricts the prior to the area of the simplex where $\argmax  _k {"θ}_k = x$. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {FIG02}}}} \relax }}{102}{figure.caption.96}}
\newlabel{fig:app-bng:posterior-zeta-infty}{{\relax 7.3}{102}{The posterior distribution $p(\vlang \mid x)$ for various $x$ if $\zeta =\infty $, that is, if agents always pick the most likely word. The posterior restricts the prior to the area of the simplex where $\argmax _k \lang _k = x$. \figdetails {\figid {FIG02}} \relax }{figure.caption.96}{}}
\oddpage@label{37}{102}
\pgfsyspdfmark {pgfid47}{18675592}{32603445}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Measuring the distance between languages}{102}{subsection.1.7.C.3}}
\abx@aux@cite{Endres2003}
\abx@aux@cite{Briet2009}
\newlabel{SC@33}{{\caption@xref {??}{ on input line 387}}{103}{Measuring the distance between languages}{figure.caption.97}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.4}{\ignorespaces The divergence between distributions in the 2-simplex and the uniform distribution $(\nicefrac  {1}{3},\nicefrac  {1}{3}, \nicefrac  {1}{3})$ (indicated by a dot) under the Jensen-Shannon divergence. Points on the solid lines have the same distance to the uniform \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig02}}} Figure inspired by a blogpost of Lior Pachter \href  {http://liorpachter.wordpress.com/tag/jensen-shannon-metric}{liorpachter.wordpress.com/tag/jensen-shannon-metric/}} \relax }}{103}{figure.caption.97}}
\newlabel{fig:app-bng:jsd}{{\relax 7.4}{103}{The divergence between distributions in the 2-simplex and the uniform distribution $(\nicefrac {1}{3},\nicefrac {1}{3}, \nicefrac {1}{3})$ (indicated by a dot) under the Jensen-Shannon divergence. Points on the solid lines have the same distance to the uniform \figdetails {\figid {fig02} Figure inspired by a blogpost of Lior Pachter \href {http://liorpachter.wordpress.com/tag/jensen-shannon-metric}{liorpachter.wordpress.com/tag/jensen-shannon-metric/}} \relax }{figure.caption.97}{}}
\abx@aux@page{287}{103}
\abx@aux@page{288}{103}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Bayesian updating and lateral inhibition}{103}{subsection.1.7.C.4}}
\newlabel{eq:app-bng:update-sampler}{{\relax 7.42}{103}{Bayesian updating and lateral inhibition}{equation.1.7.C.42}{}}
\newlabel{eq:app-bng:update-MAP}{{\relax 7.46}{104}{Bayesian updating and lateral inhibition}{equation.1.7.C.46}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {D}Parameter space of the \textsc  {dc} language game}{104}{section.1.7.D}}
\newlabel{app:bng-params}{{D}{104}{Parameter space of the \textsc {dc} language game}{section.1.7.D}{}}
\oddpage@label{38}{104}
\pgfsyspdfmark {pgfid48}{21344675}{9968681}
\oddpage@label{39}{105}
\pgfsyspdfmark {pgfid49}{17443108}{45555380}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {E}A discrete Weibull model of population turnover}{105}{section.1.7.E}}
\newlabel{app:weibull}{{E}{105}{A discrete Weibull model of population turnover}{section.1.7.E}{}}
\newlabel{SC@34}{{\caption@xref {??}{ on input line 90}}{106}{Parameter space of the \textsc {dc} language game}{figure.caption.98}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.5}{\ignorespaces The behaviour of the Dirichlet-categorical language game across the parameter space $({"γ},{"η},{"ζ})$. Rows corresponds to life expectancies (${"γ}$); columns show the coherence, reflectance, synonymy and variability for every strategy $({"η}, {"ζ})$. See figure \ref  {fig:FIG08-bng-overview} for the typical resulting languages in the extreme cases ${"γ},{"η},{"ζ}\in \{1, \infty \}$. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {bng06}}} Every cell is an average over 20 simulation runs. $K=20$, $N=10$, $b=1$, ${"γ}=\infty $, ${"β}=30$. Simulations used a deterministic hazard function.} \relax }}{106}{figure.caption.98}}
\newlabel{fig:BNG06-parameter-space}{{\relax 7.5}{106}{The behaviour of the Dirichlet-categorical language game across the parameter space $(\gamma ,\eta ,\zeta )$. Rows corresponds to life expectancies ($\gamma $); columns show the coherence, reflectance, synonymy and variability for every strategy $(\eta , \zeta )$. See figure \ref {fig:FIG08-bng-overview} for the typical resulting languages in the extreme cases $\gamma ,\eta ,\zeta \in \{1, \infty \}$. \figdetails {\figid {bng06} Every cell is an average over 20 simulation runs. $K=20$, $N=10$, $b=1$, $\gamma =\infty $, $\beta =30$. Simulations used a deterministic hazard function.} \relax }{figure.caption.98}{}}
\abx@aux@cite{Nakagawa1975}
\abx@aux@cite{Stein1984}
\abx@aux@cite{Almalki2014}
\abx@aux@cite{Weibull1951}
\abx@aux@page{289}{107}
\oddpage@label{40}{107}
\pgfsyspdfmark {pgfid50}{13639954}{43030916}
\abx@aux@page{290}{107}
\abx@aux@page{291}{107}
\abx@aux@page{292}{107}
\abx@aux@page{293}{107}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Discrete Weibull distribution}{107}{section*.99}}
\abx@aux@page{294}{107}
\oddpage@label{41}{107}
\pgfsyspdfmark {pgfid51}{14221548}{29097125}
\abx@aux@page{295}{107}
\newlabel{SC@35}{{\caption@xref {??}{ on input line 89}}{108}{Discrete Weibull distribution}{figure.caption.100}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.6}{\ignorespaces  The Weibull distribution can model the probability that an agent dies at time $t$. {\color  {black}A.} Varying the parameters of a Weibull distribution illustrates that ${"λ}$ is a scale parameter and ${"κ}$ a shape paramater. {\color  {black}B.} If ${"κ}>1$ the Weibull is a unimodal distribution, whose variance decreases with higher ${"κ}$ (thinner lines), but for ${"κ}<1$ the distribution has no mode. When ${"κ}=1$ the Weibull reduces to a exponential distribution. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig04}}}} \relax }}{108}{figure.caption.100}}
\newlabel{fig:weibull-params}{{\relax 7.6}{108}{The Weibull distribution can model the probability that an agent dies at time $t$. \subfig {A} Varying the parameters of a Weibull distribution illustrates that $\lambda $ is a scale parameter and $\kappa $ a shape paramater. \subfig {B} If $\kappa >1$ the Weibull is a unimodal distribution, whose variance decreases with higher $\kappa $ (thinner lines), but for $\kappa <1$ the distribution has no mode. When $\kappa =1$ the Weibull reduces to a exponential distribution. \figdetails {\figid {fig04}} \relax }{figure.caption.100}{}}
\newlabel{SC@36}{{\caption@xref {??}{ on input line 101}}{108}{Discrete Weibull distribution}{figure.caption.101}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.7}{\ignorespaces The single-parameter version of the continuous and discrete Weibull distribution. {\color  {black}A.} The distributions closely line up and ${"γ}$ is easily interpretable. {\color  {black}B.} The hazard rate increases with time, thus capturing ageing effects. Note that a continuous hazard rate $h(t)$ is not a distribution and exceeds 1. \par \vspace  {.5em}{\color  {lorange}\textsc  {\textbf  {\lowercase {fig04}}}} \relax }}{108}{figure.caption.101}}
\newlabel{fig:cont-discr-weibull}{{\relax 7.7}{108}{The single-parameter version of the continuous and discrete Weibull distribution. \subfig {A} The distributions closely line up and $\gamma $ is easily interpretable. \subfig {B} The hazard rate increases with time, thus capturing ageing effects. Note that a continuous hazard rate $h(t)$ is not a distribution and exceeds 1. \figdetails {\figid {fig04}} \relax }{figure.caption.101}{}}
\abx@aux@cite{Knuth1968}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Modelling population turnover}{109}{section*.102}}
\oddpage@label{42}{109}
\pgfsyspdfmark {pgfid52}{16850788}{36826740}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {F}Reformulating the packing strategy}{109}{section.1.7.F}}
\newlabel{app:packing-strategy}{{F}{109}{Reformulating the packing strategy}{section.1.7.F}{}}
\abx@aux@page{296}{109}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline The packing strategy as a constraint on trees}{109}{section*.103}}
\abx@aux@page{297}{109}
\oddpage@label{43}{109}
\abx@aux@page{298}{109}
\abx@aux@page{299}{109}
\pgfsyspdfmark {pgfid53}{19147387}{14056328}
\newlabel{eq:app-ps:hurford-grammar}{{\relax 7.55}{109}{The packing strategy as a constraint on trees}{equation.1.7.F.55}{}}
\abx@aux@page{300}{110}
\newlabel{eq:app-ps:tree-quatre-vingt-dix-sept}{{\relax 7.56}{110}{The packing strategy as a constraint on trees}{equation.1.7.F.56}{}}
\oddpage@label{44}{110}
\abx@aux@page{301}{110}
\abx@aux@page{302}{110}
\pgfsyspdfmark {pgfid116}{17371425}{27813591}
\newlabel{eq:app-ps:packing-strategy}{{\relax 7.57}{110}{The packing strategy as a constraint on trees}{equation.1.7.F.57}{}}
\newlabel{eq:app-ps:counterexample-98}{{\relax 7.58}{110}{The packing strategy as a constraint on trees}{equation.1.7.F.58}{}}
\abx@aux@cite{Hurford1999}
\newlabel{eq:counterexample-98}{{\relax 7.59}{111}{The packing strategy as a constraint on trees}{equation.1.7.F.59}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline The packing strategy without trees}{111}{section*.104}}
\oddpage@label{45}{111}
\abx@aux@page{303}{111}
\abx@aux@page{304}{111}
\pgfsyspdfmark {pgfid227}{7344352}{30373646}
\newlabel{eq:chains}{{\relax 7.60}{111}{The packing strategy without trees}{equation.1.7.F.60}{}}
\oddpage@label{46}{111}
\abx@aux@page{305}{111}
\pgfsyspdfmark {pgfid252}{26484716}{15859097}
\abx@aux@page{306}{111}
\newlabel{eq:new-packing-strategy}{{\relax 7.61}{112}{The packing strategy without trees}{equation.1.7.F.61}{}}
\newlabel{eq:generalized-packing-strategy}{{\relax 7.62}{112}{The packing strategy without trees}{equation.1.7.F.62}{}}
\abx@aux@page{307}{112}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Limits of the packing strategy}{112}{section*.105}}
\abx@aux@page{308}{112}
\abx@aux@page{309}{112}
\abx@aux@page{310}{113}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {G}Base games}{113}{section.1.7.G}}
\newlabel{app:counting-games}{{G}{113}{Base games}{section.1.7.G}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {G.1}Implicit biases in the additive naming game}{113}{subsection.1.7.G.1}}
\newlabel{eq:app-counting-games:bias}{{\relax 7.69}{114}{Implicit biases in the additive naming game}{equation.1.7.G.69}{}}
\newlabel{eq:app-counting-games:equivalent-formulation}{{\relax 7.71}{114}{Implicit biases in the additive naming game}{equation.1.7.G.71}{}}
\newlabel{SC@37}{{\caption@xref {??}{ on input line 153}}{115}{Effect of $\xi $}{figure.caption.108}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.8}{\ignorespaces Effects of ${"ξ}$, the parameter regulating the production strategy in the additive base game. Clearly, smaller values lead to slower convergence time. \par \vspace  {.5em}{\color  {lorange} \textsc  {\textbf  {\lowercase {HUR02}}} Results shown for $N=200$, $B=10$; avg.\ of 300 runs; 1 std.\ shaded.} \relax }}{115}{figure.caption.108}}
\newlabel{fig:app-counting-games:effects-xi}{{\relax 7.8}{115}{Effects of $\xi $, the parameter regulating the production strategy in the additive base game. Clearly, smaller values lead to slower convergence time. \figdetails { \figid {HUR02} Results shown for $N=200$, $B=10$; avg.\ of 300 runs; 1 std.\ shaded.} \relax }{figure.caption.108}{}}
\newlabel{SC@38}{{\caption@xref {??}{ on input line 166}}{115}{Effect of $\xi $}{figure.caption.109}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {\relax 7.9}{\ignorespaces The effect of $K$, the number of bases, in the additive base game. \par \vspace  {.5em}{\color  {lorange} \textsc  {\textbf  {\lowercase {HUR01}}} Results shown for $N=200$, ${"ξ}=1$; avg.\ of 300 runs; 1 std.\ shaded.} \relax }}{115}{figure.caption.109}}
\newlabel{fig:app-counting-games:effect-B}{{\relax 7.9}{115}{The effect of $K$, the number of bases, in the additive base game. \figdetails { \figid {HUR01} Results shown for $N=200$, $\xi =1$; avg.\ of 300 runs; 1 std.\ shaded.} \relax }{figure.caption.109}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {G.2}Properties of the additive base game}{115}{subsection.1.7.G.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Effect of ${"ξ}$}{115}{section*.107}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline effects of the number of simple numerals}{115}{section*.110}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\nonumberline Bibliography}{117}{chapter*.111}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@page{311}{117}
\abx@aux@page{312}{117}
\abx@aux@page{313}{117}
\abx@aux@page{314}{117}
\abx@aux@page{315}{117}
\abx@aux@page{316}{117}
\abx@aux@page{317}{117}
\abx@aux@page{318}{117}
\abx@aux@page{319}{117}
\abx@aux@page{320}{117}
\abx@aux@page{321}{117}
\abx@aux@page{322}{117}
\abx@aux@page{323}{117}
\abx@aux@page{324}{117}
\abx@aux@page{325}{117}
\abx@aux@page{326}{117}
\abx@aux@page{327}{117}
\abx@aux@page{328}{117}
\abx@aux@page{329}{117}
\abx@aux@page{330}{117}
\abx@aux@page{331}{117}
\abx@aux@page{332}{117}
\abx@aux@page{333}{118}
\abx@aux@page{334}{118}
\abx@aux@page{335}{118}
\abx@aux@page{336}{118}
\abx@aux@page{337}{118}
\abx@aux@page{338}{118}
\abx@aux@page{339}{118}
\abx@aux@page{340}{118}
\abx@aux@page{341}{118}
\abx@aux@page{342}{118}
\abx@aux@page{343}{118}
\abx@aux@page{344}{118}
\abx@aux@page{345}{118}
\abx@aux@page{346}{118}
\abx@aux@page{347}{118}
\abx@aux@page{348}{118}
\abx@aux@page{349}{118}
\abx@aux@page{350}{118}
\abx@aux@page{351}{118}
\abx@aux@page{352}{118}
\abx@aux@page{353}{118}
\abx@aux@page{354}{118}
\abx@aux@page{355}{118}
\abx@aux@page{356}{118}
\abx@aux@page{357}{118}
\abx@aux@page{358}{118}
\abx@aux@page{359}{119}
\abx@aux@page{360}{119}
\abx@aux@page{361}{119}
\abx@aux@page{362}{119}
\abx@aux@page{363}{119}
\abx@aux@page{364}{119}
\abx@aux@page{365}{119}
\abx@aux@page{366}{119}
\abx@aux@page{367}{119}
\abx@aux@page{368}{119}
\abx@aux@page{369}{119}
\abx@aux@page{370}{119}
\abx@aux@page{371}{119}
\abx@aux@page{372}{119}
\abx@aux@page{373}{119}
\abx@aux@page{374}{119}
\abx@aux@page{375}{119}
\abx@aux@page{376}{119}
\abx@aux@page{377}{119}
\abx@aux@page{378}{119}
\abx@aux@page{379}{119}
\abx@aux@page{380}{119}
\abx@aux@page{381}{119}
\abx@aux@page{382}{119}
\abx@aux@page{383}{119}
\abx@aux@page{384}{120}
\abx@aux@page{385}{120}
\abx@aux@page{386}{120}
\abx@aux@page{387}{120}
\abx@aux@page{388}{120}
\abx@aux@page{389}{120}
\abx@aux@page{390}{120}
\abx@aux@page{391}{120}
\abx@aux@page{392}{120}
\abx@aux@page{393}{120}
\abx@aux@page{394}{120}
\abx@aux@page{395}{120}
\abx@aux@page{396}{120}
\abx@aux@page{397}{120}
\abx@aux@page{398}{120}
\abx@aux@page{399}{120}
\abx@aux@page{400}{120}
\abx@aux@page{401}{120}
\abx@aux@page{402}{120}
\abx@aux@page{403}{120}
\abx@aux@page{404}{120}
\abx@aux@page{405}{120}
\abx@aux@page{406}{120}
\abx@aux@page{407}{120}
\abx@aux@page{408}{121}
\abx@aux@page{409}{121}
\global\@altsecnumformattrue
