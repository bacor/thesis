\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{biblatex}
\bibdata{agent-based-models-blx,~/bibliography}
\citation{biblatex-control}
\citation{Griffiths2005}
\citation{Griffiths2007a}
\citation{Griffiths2007a}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{1}{section.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Probabilistic models of iterated learning}{1}{section.2}}
\abx@aux@page{1}{1}
\abx@aux@page{2}{1}
\abx@aux@page{3}{1}
\citation{Griffiths2005}
\citation{Griffiths2007a}
\citation{Burkett2010}
\citation{Whalen2017}
\citation{Griffiths2007a}
\citation{Griffiths2007a}
\citation{Kirby2007}
\citation{Brochhagen2016}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Bayesian iterated learning}{2}{subsection.2.1}}
\newlabel{eq:iterated-learning}{{1}{2}{Bayesian iterated learning}{equation.2.1}{}}
\newlabel{eq:markov-chain}{{2}{2}{Bayesian iterated learning}{equation.2.2}{}}
\abx@aux@page{4}{2}
\abx@aux@page{5}{2}
\abx@aux@page{6}{2}
\abx@aux@page{7}{2}
\abx@aux@page{8}{2}
\oddpage@label{1}{2}
\pgfsyspdfmark {pgfid1}{32990158}{11651658}
\abx@aux@page{9}{2}
\citation{Griffiths2005}
\citation{Griffiths2007}
\citation{Burkett2010}
\citation{Kirby2015}
\citation{Griffiths2005}
\abx@aux@page{10}{3}
\abx@aux@page{11}{3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline A binary language}{3}{section*.2}}
\abx@aux@page{12}{3}
\abx@aux@page{13}{3}
\abx@aux@page{14}{3}
\abx@aux@page{15}{3}
\abx@aux@page{16}{3}
\citation{Griffiths2005}
\citation{Griffiths2007}
\citation{Kirby2007}
\citation{Smith2009}
\citation{Ferdinand2009}
\citation{Niyogi2009}
\citation{Griffiths2007a}
\citation{Burkett2010}
\citation{Kirby2015}
\citation{Ferdinand2009}
\citation{Jacoby2017}
\citation{Madsen2015a}
\citation{Norris1997}
\abx@aux@page{17}{4}
\abx@aux@page{18}{4}
\abx@aux@page{19}{4}
\abx@aux@page{20}{4}
\abx@aux@page{21}{4}
\abx@aux@page{22}{4}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Converging Markov chains}{4}{subsection.2.2}}
\oddpage@label{2}{4}
\abx@aux@page{28}{4}
\abx@aux@page{29}{4}
\pgfsyspdfmark {pgfid2}{26496398}{19186760}
\newlabel{eq:markov-example}{{8}{4}{Converging Markov chains}{equation.2.8}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces My caption\relax }}{5}{table.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{my-label}{{1}{5}{My caption\relax }{table.caption.3}{}}
\newlabel{eq:markov-assumption}{{9}{5}{Converging Markov chains}{equation.2.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline stationary distributions}{5}{section*.4}}
\citation{Madsen2015a}
\abx@aux@page{30}{6}
\newlabel{eq:convergence-markov-example}{{10}{6}{stationary distributions}{equation.2.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Irreducibility}{6}{section*.5}}
\citation{Norris1997}
\citation{Norris1997}
\oddpage@label{3}{7}
\pgfsyspdfmark {pgfid5}{12124291}{33011540}
\oddpage@label{4}{7}
\pgfsyspdfmark {pgfid6}{13678805}{27962612}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline aperiodicity}{7}{section*.6}}
\oddpage@label{5}{7}
\pgfsyspdfmark {pgfid8}{18480245}{16932072}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline ergodicity}{7}{section*.7}}
\newlabel{thm:convergence}{{1}{7}{1.8.3 in \cite {Norris1997}}{theorem.1}{}}
\abx@aux@page{31}{7}
\citation{Norris1997}
\citation{Griffiths2005}
\citation{Griffiths2005}
\abx@aux@page{32}{8}
\abx@aux@page{33}{8}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Convergence to the prior}{8}{subsection.2.3}}
\newlabel{eq:iterated-learning-chain}{{15}{8}{Convergence to the prior}{equation.2.15}{}}
\abx@aux@page{34}{8}
\citation{Griffiths2005}
\abx@aux@page{35}{9}
\abx@aux@page{36}{9}
\newlabel{eq:mc-interpretations}{{16}{9}{Convergence to the prior}{equation.2.16}{}}
\newlabel{eq:to-prove-convergence}{{17}{9}{Convergence to the prior}{equation.2.17}{}}
\newlabel{eq:proof-conv-to-the-prior}{{18}{9}{Convergence to the prior}{equation.2.18}{}}
\citation{Griffiths2007a}
\citation{Griffiths2007a}
\citation{Griffiths2005}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Different Markov chains hidden in the Bayesian iterated learning model. Figure adapted from \textcite {Griffiths2007a}.\relax }}{10}{figure.caption.8}}
\newlabel{fig:gk-markov-chains}{{1}{10}{Different Markov chains hidden in the Bayesian iterated learning model. Figure adapted from \textcite {Griffiths2007a}.\relax }{figure.caption.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline evolution of compositionality}{10}{section*.9}}
\abx@aux@page{39}{10}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline samplers and maximizers}{10}{section*.10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Population structure}{11}{section*.11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline conclusions}{11}{section*.12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Jacoby}{11}{subsubsection.2.3.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Empirical studies}{11}{subsection.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Kirby 2008}{11}{subsubsection.2.4.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Carr: color terms}{11}{subsubsection.2.4.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Tessa Verhoef?}{11}{subsubsection.2.4.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Iterated learning with counting agents?}{11}{section.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}...}{11}{subsection.3.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}...}{11}{subsection.3.2}}
\citation{Tamariz2017}
\citation{Tamariz2017}
\citation{Kirby2008}
\citation{Griffiths2007a}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Social learning paradigms in different population types. Adapted from \textcite {Tamariz2017}\relax }}{12}{figure.caption.13}}
\newlabel{fig:social-learning-paradigms}{{2}{12}{Social learning paradigms in different population types. Adapted from \textcite {Tamariz2017}\relax }{figure.caption.13}{}}
\abx@aux@page{42}{12}
\abx@aux@page{43}{12}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Modelling of serial reproduction}{12}{section.4}}
\newlabel{eq:iterated-learning}{{23}{12}{Modelling of serial reproduction}{equation.4.23}{}}
\citation{Griffiths2005}
\citation{Griffiths2007a}
\citation{Burkett2010}
\citation{Whalen2017}
\citation{Griffiths2007a}
\citation{Griffiths2007a}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Probabilistic serial reproduction}{13}{section*.14}}
\newlabel{eq:markov-chain}{{24}{13}{Probabilistic serial reproduction}{equation.4.24}{}}
\oddpage@label{6}{13}
\pgfsyspdfmark {pgfid9}{27037862}{40367923}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Bayesian serial reproduction}{13}{section*.15}}
\abx@aux@page{44}{13}
\abx@aux@page{45}{13}
\abx@aux@page{46}{13}
\abx@aux@page{47}{13}
\abx@aux@page{48}{13}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Convergence to the prior}{13}{section*.16}}
\abx@aux@page{49}{13}
\citation{Griffiths2007a}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces To do.\relax }}{14}{figure.caption.17}}
\newlabel{fig:gk-markov-chains}{{3}{14}{To do.\relax }{figure.caption.17}{}}
\newlabel{eq:mc-interpretations}{{27}{14}{Convergence to the prior}{equation.4.27}{}}
\abx@aux@page{50}{14}
\citation{Griffiths2007a}
\citation{Burkett2010}
\citation{Kirby2015}
\citation{Ferdinand2008}
\citation{Jacoby2017}
\citation{Carr2016}
\citation{Carr2016}
\citation{Griffiths2007a}
\citation{Jacoby2017}
\citation{Griffiths2007a}
\citation{Jacoby2017}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Simulation of 10.000 serial reproductions of a three-component Gaussian mixture. \textbf  {Top:} On the left the first 100 iterations of four different chains are shown. They all quickly converge to the modes (see also below), but do sometimes jump between them. On the right, the next 10000 iterations of the black chain are shown. Here the jumping is even clearer. \textbf  {Middle:} density estimates of the distribution of points visited by the black chain, up to a certain point. The further you get in the chain, the closer this distribution approximates the prior (shown in the background). This is the \emph  {convergence to the prior} from \textcite {Griffiths2007a}. \textbf  {Bottom:} The first 20 iterations for 50 \emph  {different} chains, with starting positions that are evenly spread across the unit interval. The chains very quickly converge to the modes, which seems to correspond to the convergence modelled in \textcite {Jacoby2017} (and other empirical studies). Crucially, it is not the same 'convergence to the prior'.\relax }}{15}{figure.caption.20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Linguistic and categorical \textsc  {sr}{}}{15}{section*.18}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces My caption\relax }}{16}{table.caption.19}}
\newlabel{my-label}{{2}{16}{My caption\relax }{table.caption.19}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Languages and category structures}{17}{section.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Iterated learning with probabilistic programs}{18}{section.6}}
